{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from time import time\n",
    "from csv import DictReader\n",
    "from math import exp, log, sqrt\n",
    "from random import random\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from ml_metrics_auc import auc # 추가(Diaman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A, paths\n",
    "train='train_sample_df_2.csv'\n",
    "test='test_sample_df_2.csv'\n",
    "submission = 'ftrlsub.csv'  # path of to be outputted submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B, model\n",
    "alpha = .1  # learning rate\n",
    "beta = 1.   # smoothing parameter for adaptive learning rate\n",
    "L1 = 1.     # L1 regularization, larger value means more regularized\n",
    "L2 = 0.     # L2 regularization, larger value means more regularized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C, feature/hash trick\n",
    "D = 2 ** 24             # number of weights to use\n",
    "                        # 우리 데이터의 경우 : (OHE 만들어 놨다는 가정하에)변수의 개수\n",
    "interaction = False     # whether to enable poly2 feature interactions\n",
    "\n",
    "# D, training/validation\n",
    "epoch = 1       # learn training data for N passes\n",
    "holdafter = None   # data after date N (exclusive) are used as validation\n",
    "holdout = None  # use every N training instance for holdout validation\n",
    "\n",
    "show_auc = False # 추가(Diaman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# class, function, generator definitions #####################################\n",
    "##############################################################################\n",
    "\n",
    "class ftrl_proximal(object):\n",
    "    ''' Our main algorithm: Follow the regularized leader - proximal\n",
    "\n",
    "        In short,\n",
    "        this is an adaptive-learning-rate sparse logistic-regression with\n",
    "        efficient L1-L2-regularization\n",
    "\n",
    "        Reference:\n",
    "        http://www.eecs.tufts.edu/~dsculley/papers/ad-click-prediction.pdf\n",
    "    '''\n",
    "\n",
    "    def __init__(self, alpha, beta, L1, L2, D, interaction):\n",
    "        # parameters\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.L1 = L1\n",
    "        self.L2 = L2\n",
    "\n",
    "        # feature related parameters\n",
    "        self.D = D\n",
    "        self.interaction = interaction\n",
    "\n",
    "        # model\n",
    "        # n: squared sum of past gradients\n",
    "        # z: weights\n",
    "        # w: lazy weights\n",
    "        self.n = [0.] * D\n",
    "        \n",
    "    \n",
    "        self.z = [random() for k in range(D)]#[0.] * D\n",
    "        self.w = {}\n",
    "\n",
    "    def _indices(self, x):\n",
    "        ''' A helper generator that yields the indices in x\n",
    "\n",
    "            The purpose of this generator is to make the following\n",
    "            code a bit cleaner when doing feature interaction.\n",
    "        '''\n",
    "\n",
    "        # first yield index of the bias term\n",
    "        yield 0\n",
    "\n",
    "        # then yield the normal indices\n",
    "        for index in x:  # hash 처리 된 x값\n",
    "            yield index\n",
    "            \n",
    "\n",
    "    def predict(self, x):\n",
    "        ''' Get probability estimation on x\n",
    "\n",
    "            INPUT:\n",
    "                x: features\n",
    "\n",
    "            OUTPUT:\n",
    "                probability of p(y = 1 | x; w)\n",
    "        '''\n",
    "\n",
    "        # parameters\n",
    "        alpha = self.alpha\n",
    "        beta = self.beta\n",
    "        L1 = self.L1\n",
    "        L2 = self.L2\n",
    "\n",
    "        # model\n",
    "        n = self.n\n",
    "        z = self.z\n",
    "        w = {}\n",
    "\n",
    "        # wTx is the inner product of w and x\n",
    "        wTx = 0.\n",
    "        for i in self._indices(x):  # 인덱스 존재하는 값만 w를 계산\n",
    "                                    # 우리의 경우 nonzero x를 가져오면 됨\n",
    "            sign = -1. if z[i] < 0 else 1.  # get sign of z[i]\n",
    "\n",
    "            # build w on the fly using z and n, hence the name - lazy weights\n",
    "            # we are doing this at prediction instead of update time is because\n",
    "            # this allows us for not storing the complete w\n",
    "            if sign * z[i] <= L1:\n",
    "                # w[i] vanishes due to L1 regularization\n",
    "                w[i] = 0.\n",
    "            else:\n",
    "                # apply prediction time L1, L2 regularization to z and get w\n",
    "                w[i] = (sign * L1 - z[i]) / ((beta + sqrt(n[i])) / alpha + L2)\n",
    "\n",
    "            wTx += w[i]\n",
    "\n",
    "        # cache the current w for update stage\n",
    "        self.w = w\n",
    "\n",
    "        # bounded sigmoid function, this is the probability estimation\n",
    "        return 1. / (1. + exp(-max(min(wTx, 35.), -35.)))\n",
    "\n",
    "    def update(self, x, p, y):\n",
    "        ''' Update model using x, p, y\n",
    "\n",
    "            INPUT:\n",
    "                x: feature, a list of indices\n",
    "                p: click probability prediction of our model\n",
    "                y: answer\n",
    "\n",
    "            MODIFIES:\n",
    "                self.n: increase by squared gradient\n",
    "                self.z: weights\n",
    "        '''\n",
    "\n",
    "        # parameter\n",
    "        alpha = self.alpha\n",
    "\n",
    "        # model\n",
    "        n = self.n\n",
    "        z = self.z\n",
    "        w = self.w\n",
    "\n",
    "        # gradient under logloss\n",
    "        g = p - y\n",
    "\n",
    "        # update z and n\n",
    "        for i in self._indices(x):\n",
    "            sigma = (sqrt(n[i] + g * g) - sqrt(n[i])) / alpha\n",
    "            z[i] += g - sigma * w[i]\n",
    "            n[i] += g * g\n",
    "\n",
    "\n",
    "def logloss(p, y):\n",
    "    ''' FUNCTION: Bounded logloss\n",
    "\n",
    "        INPUT:\n",
    "            p: our prediction\n",
    "            y: real answer\n",
    "\n",
    "        OUTPUT:\n",
    "            logarithmic loss of p given y\n",
    "    '''\n",
    "\n",
    "    p = max(min(p, 1. - 10e-15), 10e-15)\n",
    "    return -log(p) if y == 1. else -log(1. - p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data(path, D):\n",
    "    ''' GENERATOR: Apply hash-trick to the original csv row\n",
    "                   and for simplicity, we one-hot-encode everything\n",
    "\n",
    "        INPUT:\n",
    "            path: path to training or testing file\n",
    "            D: the max index that we can hash to\n",
    "\n",
    "        YIELDS:\n",
    "            ID: id of the instance, mainly useless\n",
    "            x: a list of hashed and one-hot-encoded 'indices'\n",
    "               we only need the index since all values are either 0 or 1\n",
    "            y: y = 1 if we have a click, else we have y = 0\n",
    "    '''\n",
    "\n",
    "    for t, row in enumerate(DictReader(open(path), delimiter=',')):\n",
    "        # process id\n",
    "        #print row\n",
    "        \n",
    "        try:\n",
    "            display_id = row['display_id']\n",
    "            ad_id = row['ad_id']\n",
    "            timestamp_event = row['timestamp_event']\n",
    "            is_leak = row['is_leak']\n",
    "            day_event = row['day_event']\n",
    "            \n",
    "            del row['display_id']\n",
    "            del row['ad_id']\n",
    "            del row['timestamp_event']\n",
    "            del row['is_leak']\n",
    "            del row['day_event']\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "        # process clicks\n",
    "        y = 0.\n",
    "        target='label'#'IsClick' \n",
    "        if target in row:\n",
    "            if row[target] == '1':\n",
    "                y = 1.\n",
    "            del row[target]\n",
    "\n",
    "        # extract date\n",
    "\n",
    "        # turn hour really into hour, it was originally YYMMDDHH\n",
    "\n",
    "        # build x\n",
    "        x = []\n",
    "        for key in row:\n",
    "            value = row[key]\n",
    "\n",
    "            # one-hot encode everything with hash trick\n",
    "            index = abs(hash(key + '_' + value)) % D\n",
    "            x.append(index)\n",
    "\n",
    "        yield t, display_id, ad_id,  x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainning models...\n",
      "2018-12-10 16:19:30.384387\tencountered: 10000\tcurrent logloss: 0.467183\n",
      "2018-12-10 16:19:31.020272\tencountered: 20000\tcurrent logloss: 0.464576\n",
      "2018-12-10 16:19:31.670658\tencountered: 30000\tcurrent logloss: 0.437086\n",
      "2018-12-10 16:19:32.325855\tencountered: 40000\tcurrent logloss: 0.452525\n",
      "2018-12-10 16:19:32.961398\tencountered: 50000\tcurrent logloss: 0.458536\n",
      "2018-12-10 16:19:33.598099\tencountered: 60000\tcurrent logloss: 0.457684\n",
      "2018-12-10 16:19:34.233378\tencountered: 70000\tcurrent logloss: 0.450643\n",
      "2018-12-10 16:19:34.871292\tencountered: 80000\tcurrent logloss: 0.448569\n",
      "2018-12-10 16:19:35.507794\tencountered: 90000\tcurrent logloss: 0.448966\n",
      "2018-12-10 16:19:36.147967\tencountered: 100000\tcurrent logloss: 0.447056\n",
      "2018-12-10 16:19:36.786914\tencountered: 110000\tcurrent logloss: 0.450472\n",
      "2018-12-10 16:19:37.429814\tencountered: 120000\tcurrent logloss: 0.453173\n",
      "2018-12-10 16:19:38.070055\tencountered: 130000\tcurrent logloss: 0.449046\n",
      "2018-12-10 16:19:38.712383\tencountered: 140000\tcurrent logloss: 0.450029\n",
      "2018-12-10 16:19:39.352187\tencountered: 150000\tcurrent logloss: 0.452337\n",
      "2018-12-10 16:19:39.994950\tencountered: 160000\tcurrent logloss: 0.451479\n",
      "2018-12-10 16:19:40.639888\tencountered: 170000\tcurrent logloss: 0.452013\n",
      "2018-12-10 16:19:41.279314\tencountered: 180000\tcurrent logloss: 0.448758\n",
      "2018-12-10 16:19:41.917937\tencountered: 190000\tcurrent logloss: 0.451584\n",
      "2018-12-10 16:19:42.562268\tencountered: 200000\tcurrent logloss: 0.453435\n",
      "2018-12-10 16:19:43.202987\tencountered: 210000\tcurrent logloss: 0.455366\n",
      "2018-12-10 16:19:43.843867\tencountered: 220000\tcurrent logloss: 0.452884\n",
      "2018-12-10 16:19:44.507660\tencountered: 230000\tcurrent logloss: 0.454153\n",
      "2018-12-10 16:19:45.142369\tencountered: 240000\tcurrent logloss: 0.455997\n",
      "2018-12-10 16:19:45.779504\tencountered: 250000\tcurrent logloss: 0.457014\n",
      "2018-12-10 16:19:46.415765\tencountered: 260000\tcurrent logloss: 0.457388\n",
      "2018-12-10 16:19:47.052109\tencountered: 270000\tcurrent logloss: 0.456769\n",
      "2018-12-10 16:19:47.685898\tencountered: 280000\tcurrent logloss: 0.458187\n",
      "2018-12-10 16:19:48.323476\tencountered: 290000\tcurrent logloss: 0.457821\n",
      "2018-12-10 16:19:48.964496\tencountered: 300000\tcurrent logloss: 0.458113\n",
      "2018-12-10 16:19:49.605009\tencountered: 310000\tcurrent logloss: 0.460238\n",
      "2018-12-10 16:19:50.245097\tencountered: 320000\tcurrent logloss: 0.459886\n",
      "2018-12-10 16:19:50.890468\tencountered: 330000\tcurrent logloss: 0.458158\n",
      "2018-12-10 16:19:51.532269\tencountered: 340000\tcurrent logloss: 0.457968\n",
      "2018-12-10 16:19:52.174459\tencountered: 350000\tcurrent logloss: 0.455718\n",
      "2018-12-10 16:19:52.822593\tencountered: 360000\tcurrent logloss: 0.455102\n",
      "2018-12-10 16:19:53.460656\tencountered: 370000\tcurrent logloss: 0.452866\n",
      "2018-12-10 16:19:54.103283\tencountered: 380000\tcurrent logloss: 0.453315\n",
      "2018-12-10 16:19:54.746321\tencountered: 390000\tcurrent logloss: 0.453540\n",
      "2018-12-10 16:19:55.386357\tencountered: 400000\tcurrent logloss: 0.455283\n",
      "2018-12-10 16:19:56.025195\tencountered: 410000\tcurrent logloss: 0.456474\n",
      "2018-12-10 16:19:56.667315\tencountered: 420000\tcurrent logloss: 0.456666\n",
      "2018-12-10 16:19:57.316787\tencountered: 430000\tcurrent logloss: 0.454936\n",
      "2018-12-10 16:19:57.982161\tencountered: 440000\tcurrent logloss: 0.453677\n",
      "2018-12-10 16:19:58.618788\tencountered: 450000\tcurrent logloss: 0.453535\n",
      "2018-12-10 16:19:59.258233\tencountered: 460000\tcurrent logloss: 0.453437\n",
      "2018-12-10 16:19:59.893270\tencountered: 470000\tcurrent logloss: 0.453838\n",
      "2018-12-10 16:20:00.528574\tencountered: 480000\tcurrent logloss: 0.454507\n",
      "2018-12-10 16:20:01.163810\tencountered: 490000\tcurrent logloss: 0.454035\n",
      "2018-12-10 16:20:01.809401\tencountered: 500000\tcurrent logloss: 0.454572\n",
      "2018-12-10 16:20:02.449557\tencountered: 510000\tcurrent logloss: 0.454845\n",
      "2018-12-10 16:20:03.086644\tencountered: 520000\tcurrent logloss: 0.454147\n",
      "2018-12-10 16:20:03.728451\tencountered: 530000\tcurrent logloss: 0.454472\n",
      "2018-12-10 16:20:04.367846\tencountered: 540000\tcurrent logloss: 0.454024\n",
      "2018-12-10 16:20:05.002574\tencountered: 550000\tcurrent logloss: 0.454099\n",
      "2018-12-10 16:20:05.634185\tencountered: 560000\tcurrent logloss: 0.454770\n",
      "2018-12-10 16:20:06.270388\tencountered: 570000\tcurrent logloss: 0.455203\n",
      "2018-12-10 16:20:06.908128\tencountered: 580000\tcurrent logloss: 0.454928\n",
      "2018-12-10 16:20:07.548480\tencountered: 590000\tcurrent logloss: 0.454943\n",
      "2018-12-10 16:20:08.192476\tencountered: 600000\tcurrent logloss: 0.455023\n",
      "2018-12-10 16:20:08.836254\tencountered: 610000\tcurrent logloss: 0.455341\n",
      "2018-12-10 16:20:09.479130\tencountered: 620000\tcurrent logloss: 0.454750\n",
      "2018-12-10 16:20:10.122228\tencountered: 630000\tcurrent logloss: 0.454747\n",
      "2018-12-10 16:20:10.766227\tencountered: 640000\tcurrent logloss: 0.454923\n",
      "2018-12-10 16:20:11.409431\tencountered: 650000\tcurrent logloss: 0.455643\n",
      "2018-12-10 16:20:12.054077\tencountered: 660000\tcurrent logloss: 0.455006\n",
      "2018-12-10 16:20:12.698433\tencountered: 670000\tcurrent logloss: 0.455070\n",
      "2018-12-10 16:20:13.345194\tencountered: 680000\tcurrent logloss: 0.455382\n",
      "2018-12-10 16:20:13.985327\tencountered: 690000\tcurrent logloss: 0.455550\n",
      "2018-12-10 16:20:14.627145\tencountered: 700000\tcurrent logloss: 0.455593\n",
      "2018-12-10 16:20:15.266669\tencountered: 710000\tcurrent logloss: 0.456089\n",
      "2018-12-10 16:20:15.908609\tencountered: 720000\tcurrent logloss: 0.455906\n",
      "2018-12-10 16:20:16.549149\tencountered: 730000\tcurrent logloss: 0.455232\n",
      "2018-12-10 16:20:17.188445\tencountered: 740000\tcurrent logloss: 0.455343\n",
      "2018-12-10 16:20:17.827280\tencountered: 750000\tcurrent logloss: 0.455478\n",
      "2018-12-10 16:20:18.461439\tencountered: 760000\tcurrent logloss: 0.452348\n",
      "2018-12-10 16:20:19.105121\tencountered: 770000\tcurrent logloss: 0.450014\n",
      "2018-12-10 16:20:19.749417\tencountered: 780000\tcurrent logloss: 0.449295\n",
      "2018-12-10 16:20:20.387106\tencountered: 790000\tcurrent logloss: 0.448567\n",
      "2018-12-10 16:20:21.022766\tencountered: 800000\tcurrent logloss: 0.448121\n",
      "2018-12-10 16:20:21.662606\tencountered: 810000\tcurrent logloss: 0.446801\n",
      "2018-12-10 16:20:22.304260\tencountered: 820000\tcurrent logloss: 0.445449\n",
      "2018-12-10 16:20:22.945646\tencountered: 830000\tcurrent logloss: 0.445408\n",
      "2018-12-10 16:20:23.580112\tencountered: 840000\tcurrent logloss: 0.444649\n",
      "2018-12-10 16:20:24.221085\tencountered: 850000\tcurrent logloss: 0.445191\n",
      "2018-12-10 16:20:24.871823\tencountered: 860000\tcurrent logloss: 0.445305\n",
      "2018-12-10 16:20:25.523869\tencountered: 870000\tcurrent logloss: 0.445007\n",
      "2018-12-10 16:20:26.171093\tencountered: 880000\tcurrent logloss: 0.444569\n",
      "2018-12-10 16:20:26.847908\tencountered: 890000\tcurrent logloss: 0.445264\n",
      "2018-12-10 16:20:27.508476\tencountered: 900000\tcurrent logloss: 0.445357\n",
      "2018-12-10 16:20:28.188630\tencountered: 910000\tcurrent logloss: 0.445724\n",
      "2018-12-10 16:20:28.843089\tencountered: 920000\tcurrent logloss: 0.444727\n",
      "2018-12-10 16:20:29.526703\tencountered: 930000\tcurrent logloss: 0.444536\n",
      "2018-12-10 16:20:30.173397\tencountered: 940000\tcurrent logloss: 0.443992\n",
      "2018-12-10 16:20:30.817388\tencountered: 950000\tcurrent logloss: 0.444303\n",
      "2018-12-10 16:20:31.452647\tencountered: 960000\tcurrent logloss: 0.443147\n",
      "2018-12-10 16:20:32.090986\tencountered: 970000\tcurrent logloss: 0.442885\n",
      "2018-12-10 16:20:32.732670\tencountered: 980000\tcurrent logloss: 0.443191\n",
      "2018-12-10 16:20:33.372218\tencountered: 990000\tcurrent logloss: 0.442883\n",
      "2018-12-10 16:20:34.004020\tencountered: 1000000\tcurrent logloss: 0.443282\n",
      "2018-12-10 16:20:34.641866\tencountered: 1010000\tcurrent logloss: 0.443330\n",
      "2018-12-10 16:20:35.282289\tencountered: 1020000\tcurrent logloss: 0.443441\n",
      "2018-12-10 16:20:35.936604\tencountered: 1030000\tcurrent logloss: 0.443700\n",
      "training took 1.153m\n"
     ]
    }
   ],
   "source": [
    "# ##############################################################################\n",
    "# start training #############################################################\n",
    "##############################################################################\n",
    "\n",
    "start = time()\n",
    "\n",
    "# initialize ourselves a learner\n",
    "learner = ftrl_proximal(alpha, beta, L1, L2, D, interaction)\n",
    "\n",
    "# start training\n",
    "print('trainning models...')\n",
    "\n",
    "for e in range(epoch):\n",
    "    loss = 0.\n",
    "    count = 0\n",
    "    for t, display_id, ad_id, x, y in data(train, D):  # data is a generator\n",
    "\n",
    "        p = learner.predict(x)\n",
    "        loss += logloss(p, y)\n",
    "        learner.update(x, p, y)\n",
    "        count+=1\n",
    "        if count%10000==0:\n",
    "            #print count,loss/count\n",
    "            print('%s\\tencountered: %d\\tcurrent logloss: %f' % (\n",
    "                datetime.now(), count, loss/count))\n",
    "            # x = count, y = loss/count로 plot 그리기\n",
    "            \n",
    "count=0\n",
    "loss=0\n",
    "\n",
    "\n",
    "print('training took %0.3fm' % ((time() - start) / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auc \n",
    "def tied_rank(x):\n",
    "    \"\"\"\n",
    "    Computes the tied rank of elements in x.\n",
    "    This function computes the tied rank of elements in x.\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : list of numbers, numpy array\n",
    "    Returns\n",
    "    -------\n",
    "    score : list of numbers\n",
    "            The tied rank f each element in x\n",
    "    \"\"\"\n",
    "    sorted_x = sorted(zip(x,range(len(x))))\n",
    "    r = [0 for k in x]\n",
    "    cur_val = sorted_x[0][0]\n",
    "    last_rank = 0\n",
    "    for i in range(len(sorted_x)):\n",
    "        if cur_val != sorted_x[i][0]:\n",
    "            cur_val = sorted_x[i][0]\n",
    "            for j in range(last_rank, i): \n",
    "                r[sorted_x[j][1]] = float(last_rank+1+i)/2.0\n",
    "            last_rank = i\n",
    "        if i==len(sorted_x)-1:\n",
    "            for j in range(last_rank, i+1): \n",
    "                r[sorted_x[j][1]] = float(last_rank+i+2)/2.0\n",
    "    return r\n",
    "\n",
    "def auc(y, p):\n",
    "    \"\"\"\n",
    "    Computes the area under the receiver-operater characteristic (AUC)\n",
    "    This function computes the AUC error metric for binary classification.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list of binary numbers, numpy array\n",
    "             The ground truth value\n",
    "    posterior : same type as actual\n",
    "                Defines a ranking on the binary numbers, from most likely to\n",
    "                be positive to least likely to be positive.\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The mean squared error between actual and posterior\n",
    "    \"\"\"\n",
    "    r = tied_rank(p)\n",
    "    num_positive = len([0 for x in y if x==1])\n",
    "    num_negative = len(y)-num_positive\n",
    "    sum_positive = sum([r[i] for i in range(len(r)) if y[i]==1])\n",
    "    auc = ((sum_positive - num_positive*(num_positive+1)/2.0) /\n",
    "           (num_negative*num_positive))\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating models...\n",
      "processed 200000th row\n",
      "processed 400000th row\n",
      "processed 600000th row\n",
      "processed 800000th row\n",
      "processed 1000000th row\n",
      "final auc: 0.7284\n",
      "predict took 1.310m\n"
     ]
    }
   ],
   "source": [
    "# validation\n",
    "\n",
    "print('validating models...')\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "all_y = []\n",
    "all_pred = []\n",
    "\n",
    "f_pred = [] \n",
    "f_pred = open('ftrl_pred.txt','w')\n",
    "f_pred.write('y_actual,y_pred\\n')\n",
    "\n",
    "\n",
    "for e in range(epoch):\n",
    "    loss = 0.\n",
    "    count = 0\n",
    "    for t, display_id, ad_id, x, y in data(train, D):  # data is a generator\n",
    "\n",
    "        p = learner.predict(x)\n",
    "        loss += logloss(p, y)\n",
    "        learner.update(x, p, y)\n",
    "        count+=1\n",
    "        \n",
    "        all_y.append(y)\n",
    "        all_pred.append(p)\n",
    "        f_pred.write('%s,%s\\n' % (y, p))\n",
    "\n",
    "        if count % 200000 == 0:\n",
    "          print('processed %dth row' % count)\n",
    "        if show_auc:\n",
    "          pred_auc = auc(all_y, all_pred)\n",
    "          \n",
    "          \n",
    "pred_auc = auc(all_y, all_pred)          \n",
    "print('final auc: %.4f' % pred_auc)\n",
    "\n",
    "f_pred.close()  \n",
    "\n",
    "print('predict took %0.3fm' % ((time() - t0) / 60))\n",
    "del all_y, all_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(submission, 'w') as outfile:\n",
    "    outfile.write('display_id,ad_id, prob\\n')\n",
    "    for t, display_id, ad_id, x, y in data(test, D):\n",
    "        p = learner.predict(x)\n",
    "        outfile.write('%s,%s,%s\\n' % (display_id, ad_id, str(p)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# map score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ml_metrics\n",
      "  Downloading https://files.pythonhosted.org/packages/c1/e7/c31a2dd37045a0c904bee31c2dbed903d4f125a6ce980b91bae0c961abb8/ml_metrics-0.1.4.tar.gz\n",
      "Requirement already satisfied: numpy in /usr/local/envs/py3env/lib/python3.5/site-packages (from ml_metrics) (1.14.0)\n",
      "Requirement already satisfied: pandas in /usr/local/envs/py3env/lib/python3.5/site-packages (from ml_metrics) (0.22.0)\n",
      "Requirement already satisfied: python-dateutil>=2 in /usr/local/envs/py3env/lib/python3.5/site-packages (from pandas->ml_metrics) (2.5.0)\n",
      "Requirement already satisfied: pytz>=2011k in /usr/local/envs/py3env/lib/python3.5/site-packages (from pandas->ml_metrics) (2018.4)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/envs/py3env/lib/python3.5/site-packages (from python-dateutil>=2->pandas->ml_metrics) (1.10.0)\n",
      "Building wheels for collected packages: ml-metrics\n",
      "  Running setup.py bdist_wheel for ml-metrics ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/b3/61/2d/776be7b8a4f14c5db48c8e5451451cabc58dc6aa7ee3801163\n",
      "Successfully built ml-metrics\n",
      "Installing collected packages: ml-metrics\n",
      "Successfully installed ml-metrics-0.1.4\n"
     ]
    }
   ],
   "source": [
    "!pip3 install ml_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from ml_metrics import mapk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>display_id</th>\n",
       "      <th>ad_id</th>\n",
       "      <th>label_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15545104</td>\n",
       "      <td>1419</td>\n",
       "      <td>0.162134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15523904</td>\n",
       "      <td>784</td>\n",
       "      <td>0.196938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16731814</td>\n",
       "      <td>949</td>\n",
       "      <td>0.233614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13517470</td>\n",
       "      <td>492732</td>\n",
       "      <td>0.299224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14303795</td>\n",
       "      <td>492733</td>\n",
       "      <td>0.438912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   display_id   ad_id   label_pred\n",
       "0    15545104    1419     0.162134\n",
       "1    15523904     784     0.196938\n",
       "2    16731814     949     0.233614\n",
       "3    13517470  492732     0.299224\n",
       "4    14303795  492733     0.438912"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# submission = df_test\n",
    "df_test = pd.read_csv(submission)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_test.columns = ['display_id', 'ad_id', 'prob']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>display_id</th>\n",
       "      <th>ad_id</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3341</th>\n",
       "      <td>13352644</td>\n",
       "      <td>6186</td>\n",
       "      <td>0.389707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6492</th>\n",
       "      <td>13352644</td>\n",
       "      <td>497731</td>\n",
       "      <td>0.153318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233265</th>\n",
       "      <td>13352644</td>\n",
       "      <td>488003</td>\n",
       "      <td>0.090401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116694</th>\n",
       "      <td>13352644</td>\n",
       "      <td>504323</td>\n",
       "      <td>0.085584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118722</th>\n",
       "      <td>13352644</td>\n",
       "      <td>138832</td>\n",
       "      <td>0.085373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201397</th>\n",
       "      <td>13352644</td>\n",
       "      <td>98307</td>\n",
       "      <td>0.073456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26566</th>\n",
       "      <td>13352758</td>\n",
       "      <td>467799</td>\n",
       "      <td>0.297327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183379</th>\n",
       "      <td>13352758</td>\n",
       "      <td>39675</td>\n",
       "      <td>0.156494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230187</th>\n",
       "      <td>13352758</td>\n",
       "      <td>459432</td>\n",
       "      <td>0.129399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212799</th>\n",
       "      <td>13352758</td>\n",
       "      <td>285722</td>\n",
       "      <td>0.127339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133818</th>\n",
       "      <td>13352762</td>\n",
       "      <td>81604</td>\n",
       "      <td>0.399835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246811</th>\n",
       "      <td>13352762</td>\n",
       "      <td>44953</td>\n",
       "      <td>0.211901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123711</th>\n",
       "      <td>13352762</td>\n",
       "      <td>367363</td>\n",
       "      <td>0.108518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79559</th>\n",
       "      <td>13352762</td>\n",
       "      <td>25876</td>\n",
       "      <td>0.096384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225383</th>\n",
       "      <td>13352762</td>\n",
       "      <td>123813</td>\n",
       "      <td>0.019577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52993</th>\n",
       "      <td>13352938</td>\n",
       "      <td>94556</td>\n",
       "      <td>0.295914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33624</th>\n",
       "      <td>13352938</td>\n",
       "      <td>470000</td>\n",
       "      <td>0.164948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42339</th>\n",
       "      <td>13352938</td>\n",
       "      <td>147920</td>\n",
       "      <td>0.162150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57961</th>\n",
       "      <td>13352938</td>\n",
       "      <td>94542</td>\n",
       "      <td>0.153190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49666</th>\n",
       "      <td>13352938</td>\n",
       "      <td>388078</td>\n",
       "      <td>0.152558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        display_id   ad_id      prob\n",
       "3341      13352644    6186  0.389707\n",
       "6492      13352644  497731  0.153318\n",
       "233265    13352644  488003  0.090401\n",
       "116694    13352644  504323  0.085584\n",
       "118722    13352644  138832  0.085373\n",
       "201397    13352644   98307  0.073456\n",
       "26566     13352758  467799  0.297327\n",
       "183379    13352758   39675  0.156494\n",
       "230187    13352758  459432  0.129399\n",
       "212799    13352758  285722  0.127339\n",
       "133818    13352762   81604  0.399835\n",
       "246811    13352762   44953  0.211901\n",
       "123711    13352762  367363  0.108518\n",
       "79559     13352762   25876  0.096384\n",
       "225383    13352762  123813  0.019577\n",
       "52993     13352938   94556  0.295914\n",
       "33624     13352938  470000  0.164948\n",
       "42339     13352938  147920  0.162150\n",
       "57961     13352938   94542  0.153190\n",
       "49666     13352938  388078  0.152558"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.sort_values(['display_id', 'prob'], inplace=True, ascending=[True, False] )\n",
    "df_test.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py3env/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (25,30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>display_id</th>\n",
       "      <th>ad_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15545104</td>\n",
       "      <td>1419</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15523904</td>\n",
       "      <td>784</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16731814</td>\n",
       "      <td>949</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13517470</td>\n",
       "      <td>492732</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14303795</td>\n",
       "      <td>492733</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   display_id   ad_id  label\n",
       "0    15545104    1419      0\n",
       "1    15523904     784      0\n",
       "2    16731814     949      0\n",
       "3    13517470  492732      1\n",
       "4    14303795  492733      1"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_test = pd.read_csv(test)\n",
    "raw_test = raw_test[['display_id','ad_id','label']]\n",
    "raw_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>display_id</th>\n",
       "      <th>ad_id</th>\n",
       "      <th>prob</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13352644</td>\n",
       "      <td>6186</td>\n",
       "      <td>0.389707</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13352644</td>\n",
       "      <td>497731</td>\n",
       "      <td>0.153318</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13352644</td>\n",
       "      <td>488003</td>\n",
       "      <td>0.090401</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13352644</td>\n",
       "      <td>504323</td>\n",
       "      <td>0.085584</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13352644</td>\n",
       "      <td>138832</td>\n",
       "      <td>0.085373</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13352644</td>\n",
       "      <td>98307</td>\n",
       "      <td>0.073456</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13352758</td>\n",
       "      <td>467799</td>\n",
       "      <td>0.297327</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13352758</td>\n",
       "      <td>39675</td>\n",
       "      <td>0.156494</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13352758</td>\n",
       "      <td>459432</td>\n",
       "      <td>0.129399</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13352758</td>\n",
       "      <td>285722</td>\n",
       "      <td>0.127339</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>13352762</td>\n",
       "      <td>81604</td>\n",
       "      <td>0.399835</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13352762</td>\n",
       "      <td>44953</td>\n",
       "      <td>0.211901</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13352762</td>\n",
       "      <td>367363</td>\n",
       "      <td>0.108518</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13352762</td>\n",
       "      <td>25876</td>\n",
       "      <td>0.096384</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>13352762</td>\n",
       "      <td>123813</td>\n",
       "      <td>0.019577</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    display_id   ad_id      prob  label\n",
       "0     13352644    6186  0.389707      1\n",
       "1     13352644  497731  0.153318      0\n",
       "2     13352644  488003  0.090401      0\n",
       "3     13352644  504323  0.085584      0\n",
       "4     13352644  138832  0.085373      0\n",
       "5     13352644   98307  0.073456      0\n",
       "6     13352758  467799  0.297327      0\n",
       "7     13352758   39675  0.156494      0\n",
       "8     13352758  459432  0.129399      1\n",
       "9     13352758  285722  0.127339      0\n",
       "10    13352762   81604  0.399835      1\n",
       "11    13352762   44953  0.211901      0\n",
       "12    13352762  367363  0.108518      0\n",
       "13    13352762   25876  0.096384      0\n",
       "14    13352762  123813  0.019577      0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = pd.merge(df_test, raw_test, on = ['display_id','ad_id'], how = 'left')\n",
    "final.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_ads = final[final.label == 1 ].ad_id.values.reshape(-1,1) # 실제 클릭된 ad_id\n",
    "P_ads = final.groupby(by='display_id', sort=False).ad_id.apply( lambda x: x.values ).values  # 예측 순서대로 나열한 ad_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6186]\n",
      " [459432]\n",
      " [ 81604]\n",
      " ...\n",
      " [492729]\n",
      " [175214]\n",
      " [179047]]\n",
      "[array([  6186, 497731, 488003, 504323, 138832,  98307])\n",
      " array([467799,  39675, 459432, 285722])\n",
      " array([ 81604,  44953, 367363,  25876, 123813]) ...\n",
      " array([492729, 235450,  63884]) array([175214,  96199,  59607, 509329])\n",
      " array([536293, 293747, 179047, 365360])]\n"
     ]
    }
   ],
   "source": [
    "print(Y_ads)\n",
    "print(P_ads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP: 0.625901380764\n"
     ]
    }
   ],
   "source": [
    "score = mapk( Y_ads, P_ads, 12 )\n",
    "print(\"MAP: %.12f\" % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
